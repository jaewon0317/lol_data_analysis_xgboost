{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-07T08:16:04.322578Z",
     "start_time": "2025-12-07T08:13:58.282583Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ==========================================\n",
    "# 0. ì„¤ì • (Configuration)\n",
    "# ==========================================\n",
    "# ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "DATA_PATH = \"data/final_features.csv\"\n",
    "\n",
    "# í•™ìŠµí•  í¬ì§€ì…˜ ëª©ë¡ (ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë¨)\n",
    "TARGET_POSITIONS = ['TOP', 'JUNGLE', 'MIDDLE', 'BOT_DUO']\n",
    "\n",
    "# [ì‚¬ìš©ì ìš”ì²­ ë°˜ì˜] ì „ì²´ 22ê°œ ì¤‘ 'level', 'levelDiff' ì œì™¸í•œ 20ê°œ Feature\n",
    "FEATURE_COLS = [\n",
    "    # ì„±ì¥\n",
    "    'xp', 'minionsKilled', 'jungleMinionsKilled',\n",
    "    # ì „íˆ¬\n",
    "    'totalDamageDoneToChampions', 'totalDamageTaken', 'timeEnemySpentControlled',\n",
    "    'kills', 'deaths', 'assists', 'soloKills',\n",
    "    # ìš´ì˜ ë° ê¸°íƒ€\n",
    "    'turretPlates', 'wardsPlaced', 'objectiveParticipation',\n",
    "    # ê²©ì°¨ (Diff)\n",
    "    'xpDiff', 'csDiff', 'damageDiff', 'killsDiff',\n",
    "    # ë¹„ìœ¨\n",
    "    'KDA', 'killParticipation', 'damageShare'\n",
    "]\n",
    "# ì œì™¸ë¨: 'level', 'levelDiff'\n",
    "\n",
    "TARGET_COL = 'totalGold'\n",
    "\n",
    "# ==========================================\n",
    "# 1. ë¡œê¹… í´ë˜ìŠ¤ & í™˜ê²½ ì„¤ì •\n",
    "# ==========================================\n",
    "class DualLogger(object):\n",
    "    def __init__(self, filename):\n",
    "        self.terminal = sys.stdout\n",
    "        self.log = open(filename, \"a\", encoding='utf-8')\n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "    def flush(self):\n",
    "        self.terminal.flush()\n",
    "        self.log.flush()\n",
    "\n",
    "# í´ë” ìƒì„±\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# ë¡œê·¸ íŒŒì¼ ì„¤ì •\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_filename = f\"logs/train_all_positions_{timestamp}.txt\"\n",
    "sys.stdout = DualLogger(log_filename)\n",
    "\n",
    "# ì‹œê°í™” í°íŠ¸ ì„¤ì • (í•œê¸€ ê¹¨ì§ ë°©ì§€)\n",
    "import platform\n",
    "system_name = platform.system()\n",
    "if system_name == 'Darwin': plt.rcParams['font.family'] = 'AppleGothic'\n",
    "elif system_name == 'Windows': plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "else: plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ==========================================\n",
    "# 2. ë°ì´í„° ë¡œë“œ (í•œ ë²ˆë§Œ ì‹¤í–‰)\n",
    "# ==========================================\n",
    "def load_data():\n",
    "    print(f\"Loading data from {DATA_PATH}...\")\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(f\"Error: ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({DATA_PATH})\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "    # 0ë¶„ ë°ì´í„° ì œê±°\n",
    "    df = df[df['minute'] > 0].reset_index(drop=True)\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (NaN -> 0, íŠ¹íˆ soloKills ë“±)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    print(f\"âœ… Data Loaded. Total Rows: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 3. í¬ì§€ì…˜ë³„ í•™ìŠµ í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def train_for_position(df, position):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸš€ Starting Training for Position: {position}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 1. í¬ì§€ì…˜ í•„í„°ë§\n",
    "    pos_df = df[df['position'] == position].reset_index(drop=True)\n",
    "\n",
    "    if len(pos_df) == 0:\n",
    "        print(f\"âš ï¸ Warning: '{position}' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ“Š Rows for {position}: {len(pos_df)}\")\n",
    "\n",
    "    # Feature í™•ì¸\n",
    "    X = pos_df[FEATURE_COLS]\n",
    "    y = pos_df[TARGET_COL]\n",
    "    groups = pos_df['matchId']\n",
    "\n",
    "    # 2. Train/Test ë¶„í•  (GroupShuffleSplit)\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    groups_test = groups.iloc[test_idx]\n",
    "\n",
    "    # 3. ëª¨ë¸ í•™ìŠµ\n",
    "    # [ìˆ˜ì •ë¨] early_stopping_roundsë¥¼ ì—¬ê¸°(ìƒì„±ì)ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='reg:squarederror',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        tree_method='hist',\n",
    "        early_stopping_rounds=50  # ğŸ‘ˆ ì—¬ê¸°ì— ì¶”ê°€!\n",
    "    )\n",
    "\n",
    "    print(f\"Training XGBoost for {position}...\")\n",
    "\n",
    "    # [ìˆ˜ì •ë¨] fit() ì•ˆì—ì„œëŠ” early_stopping_rounds ì œê±°\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # 4. í‰ê°€\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nâœ… [{position}] Evaluation:\")\n",
    "    print(f\"   MAE : {mae:.2f} Gold\")\n",
    "    print(f\"   RMSE: {rmse:.2f} Gold\")\n",
    "    print(f\"   R2  : {r2:.4f}\")\n",
    "\n",
    "    # 5. ì €ì¥ (ëª¨ë¸ & ê²°ê³¼)\n",
    "    # ëª¨ë¸ ì €ì¥\n",
    "    model_filename = f\"models/xgb_gold_predictor_{position}_{timestamp}.pkl\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"   ğŸ’¾ Model Saved: {model_filename}\")\n",
    "\n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥\n",
    "    results_df = X_test.copy()\n",
    "    results_df['actualGold'] = y_test\n",
    "    results_df['predictedGold'] = y_pred\n",
    "    results_df['error'] = results_df['predictedGold'] - results_df['actualGold']\n",
    "    results_df['matchId'] = groups_test\n",
    "    results_csv = f'output/test_predictions_{position}_{timestamp}.csv'\n",
    "    results_df.to_csv(results_csv, index=False)\n",
    "    print(f\"   ğŸ“„ Predictions Saved: {results_csv}\")\n",
    "\n",
    "    # 6. Feature Importance ì‹œê°í™”\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    xgb.plot_importance(model, max_num_features=20, importance_type='gain', height=0.6, grid=False)\n",
    "    plt.title(f'Feature Importance (Gain) - {position}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output/feature_importance_{position}_{timestamp}.png')\n",
    "    plt.close()\n",
    "    print(f\"   ğŸ“Š Plot Saved: output/feature_importance_{position}_{timestamp}.png\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. ë©”ì¸ ì‹¤í–‰\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    full_df = load_data()\n",
    "\n",
    "    # ìˆœì°¨ì ìœ¼ë¡œ ëª¨ë“  í¬ì§€ì…˜ í•™ìŠµ\n",
    "    for pos in TARGET_POSITIONS:\n",
    "        train_for_position(full_df, pos)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ‰ All Positions Trained Successfully!\")\n",
    "    print(f\"ğŸ“‚ Check 'output/' and 'models/' directories.\")\n",
    "    print(\"=\"*60)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "96878a3d3693b5c3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
